{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "merging_storic_information.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMh+E3ajuElYWjzYIHvck9A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DarioneNazionale/KickLearning/blob/main/working_on_data/merging_storic_information.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ks6L088YaPvV"
      },
      "source": [
        "## Merging the historic stada in the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd0uN6whaZ6z"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0klTDPVagiC"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TPxeRoI_yfX"
      },
      "source": [
        "historic_data_path = \"./drive/MyDrive/Project/Data\"\n",
        "data_path = \"./drive/MyDrive/Project/Data/datasets\"\n",
        "destination_path = \"./drive/MyDrive/Project/Data/complete\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMaYnna5_w-H"
      },
      "source": [
        "import os\n",
        "from os.path import join\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWMzijWHaK83"
      },
      "source": [
        "### Fetching the historic data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUvwDZX3AwD-"
      },
      "source": [
        "storic_df = pd.read_csv(join(historic_data_path, \"complete_storic_info.csv\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJv9FuwUDcFu"
      },
      "source": [
        "### Historic Info Function\n",
        "Function to be then applied on all the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zLTsPTPBm5V"
      },
      "source": [
        "def get_history(entry, storic_df):\n",
        "    reduced_storic_df = storic_df[(storic_df[\"creator_id\"] == entry[\"creator_id\"])&&(storic_df[\"id\"] != entry[\"id\"])&&(storic_df[\"time\"] < entry[\"launched_at\"])]\n",
        "    reduced_storic_df = reduced_storic_df.iloc[reduced_storic_df.groupby('id')['time'].idxmax()]\n",
        "    reduced_storic_df = reduced_storic_df.groupby('creator_id').apply(list)\n",
        "    \n",
        "    return reduced_storic_df.drop(columns=[\"id\", \"creator_id\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMvKJ-L4Z1ph"
      },
      "source": [
        "## Applying on all the dataset\n",
        "Merging the historic data with the actual one file by file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M1FTyFM-a50"
      },
      "source": [
        "file_list = sorted(filter(lambda file: file[:4]==\"file\", os.listdir(\"/content/drive/MyDrive/Second Semester/SL/Project/Data/datasets_bakup\")), reverse=True)\n",
        "\n",
        "start = time.perf_counter()\n",
        "for i, file in enumerate(file_list):\n",
        "\n",
        "    df = pd.read_csv(os.path.join(data_path, file), usecols=[\"id\", \"creator_id\", \"year\"], index_col=[0])\n",
        "\n",
        "    df_history = df.apply(lambda entry: get_history(entry, storic_df))\n",
        "\n",
        "    df = pd.concat((df, df_history), axis=1)\n",
        "\n",
        "    df.to_csv(join(destination_path, file), index=False)\n",
        "\n",
        "    if i>0 and i % round(len(file_list)/5) == 0:\n",
        "        print(f\"Time elapsed: {time.perf_counter()-start}; remaning time: {(time.perf_counter()-start)/i*(len(file_list)-i)}\")\n",
        "        print(f\"Done {round(i/len(file_list)*100)}% untill now, in total {i} files\", end=\"\\n\\n\")\n",
        "\n",
        "print(f\"Time elapsed in total: {time.perf_counter()-start}\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}