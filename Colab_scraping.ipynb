{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab_scraping.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHlQ0qH1A79i",
        "outputId": "5003d1d7-fc3b-449b-91f7-1c6b39b42723"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugdeDEGaz79t"
      },
      "source": [
        "# Filename"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_M3a-IZz0AZY"
      },
      "source": [
        "name = 'file_0.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0NhbWxjxzgG"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhGVf7B-xxnN"
      },
      "source": [
        "!pip install cchardet &> /dev/null\n",
        "!pip install requests-futures &> /dev/null\n",
        "!pip install http_request_randomizer &> /dev/null"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E70Cnbjew5zd"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0QDT6Alw-kz"
      },
      "source": [
        "from requests import Session\n",
        "from requests_futures.sessions import FuturesSession\n",
        "from bs4 import BeautifulSoup\n",
        "from os import path, mkdir\n",
        "import re\n",
        "import pandas as pd\n",
        "import time\n",
        "import cchardet\n",
        "import lxml\n",
        "from numpy import random\n",
        "from http_request_randomizer.requests.proxy.requestProxy import RequestProxy"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_uYZpmDxI4G"
      },
      "source": [
        "# Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oe_D6bUkWtt6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "91b1e0d2-b4d4-4810-e773-52be38d21a0a"
      },
      "source": [
        "req_proxy = RequestProxy()  \n",
        "proxy_list = req_proxy.get_proxy_list()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-13 17:38:13,532 http_request_randomizer.requests.useragent.userAgent INFO     Using local file for user agents: /usr/local/lib/python3.7/dist-packages/http_request_randomizer/requests/proxy/../data/user_agents.txt\n",
            "2021-05-13 17:38:13,536 root   DEBUG    === Initialized Proxy Parsers ===\n",
            "2021-05-13 17:38:13,538 root   DEBUG    \t FreeProxy parser of 'http://free-proxy-list.net' with required bandwidth: '150' KBs\n",
            "2021-05-13 17:38:13,541 root   DEBUG    \t PremProxy parser of 'https://premproxy.com/list/' with required bandwidth: '150' KBs\n",
            "2021-05-13 17:38:13,543 root   DEBUG    \t SslProxy parser of 'https://www.sslproxies.org' with required bandwidth: '150' KBs\n",
            "2021-05-13 17:38:13,545 root   DEBUG    =================================\n",
            "2021-05-13 17:38:13,787 root   DEBUG    Added 300 proxies from FreeProxy\n",
            "2021-05-13 17:38:14,645 http_request_randomizer.requests.parsers.PremProxyParser DEBUG    Pages: {'', '06.htm', '03.htm', '04.htm', '05.htm', '09.htm', '02.htm', '07.htm', '08.htm'}\n",
            "2021-05-13 17:38:15,412 http_request_randomizer.requests.parsers.js.UnPacker INFO     JS UnPacker init path: https://premproxy.com/js/67e2c.js\n",
            "2021-05-13 17:38:16,506 http_request_randomizer.requests.parsers.js.UnPacker DEBUG    portmap: {'re07d': '8080', 'r1eb2': '8087', 'r415a': '8000', 'ra406': '38009', 'r7eaf': '999', 'r94e1': '10809', 'rab83': '51200', 'rb23d': '8081', 'r7a92': '80', 'r8422': '37699', 'r717d': '21231', 'r5a03': '53281', 'r5d52': '48146', 'rb200': '3127', 'rb826': '3128', 'rcc66': '44938', 'r741e': '8123', 'r2c6b': '57797', 'rc23c': '60020', 're4d5': '55830', 'rabe0': '59152', 'rdb33': '65205', 'r523e': '45597', 'rfc7b': '8181', 'r9e9a': '55443', 'r7685': '60731', 'r6b5b': '41258', 'rb310': '59777', 'rec57': '9999', 'r1a11': '3256', 'r7443': '18080', 'r6b25': '34403', 'r1c09': '36681', 'r2c84': '59144', 'reb7f': '34273', 'rfb53': '443', 'r63e1': '32842', 'r2b91': '46611', 'r4efa': '52479', 'r9957': '3129', 'r9d37': '34560', 'rec13': '1081', 'rd475': '32768', 'r1956': '50824', 'r6b40': '42119', 'r7c29': '31870', 'r22bc': '9991', 'r2cfd': '8197', 'r4a66': '8193', 'r455e': '8888', 'r27f4': '8082', 'r20a1': '6666', 'rd9c0': '35101', 'rc852': '83', 'r3c9b': '3888', 're550': '58137', 'r9fff': '47324', 'r83c5': '6000', 'r43a3': '58888', 'r2e76': '39589', 'r820f': '45944', 'r47c4': '1328', 'r80e8': '60792', 'r17e5': '8090', 'r5439': '56644', 'rf638': '48515', 'rc41a': '31398', 'rda9a': '47615', 'r571e': '42928', 'r788b': '54018', 'r30e5': '31442', 'r77bb': '41043', 'r625d': '54555', 'r7e90': '9001', 'r4448': '23500', 'r3d2a': '42033', 'r0e10': '50128', 'r27d6': '8118', 'reb05': '47548', 'r86f7': '10000', 'ra39d': '49044', 'r4083': '38898', 'r58b4': '30389', 'rbb5e': '38615', 'r432b': '50330', 'rb406': '50782', 'r0917': '44861', 'r3ae5': '30962', 'r24b4': '44061', 'r2f72': '23352', 'rbd2f': '35953', 'r34f1': '41026', 'rb1e5': '46004', 'rfcad': '51468', 'r0e56': '61711', 'r957f': '8889', 'rb300': '53438', 'rb7b5': '36314', 'r7110': '34772', 'r998b': '43060', 'r51aa': '9090', 're830': '34638', 'rcf6b': '41201', 'r8cb8': '33855', 'r0619': '31280', 'raef7': '32345', 'r44d5': '8880', 'r7720': '40301', 'raf55': '42134', 'r928a': '43662', 're7b5': '37101', 'rdcdb': '43496', 'rd3cb': '47504', 'r03a6': '54675', 'r0756': '31932'}\n",
            "2021-05-13 17:38:20,893 root   DEBUG    Added 473 proxies from PremProxy\n",
            "2021-05-13 17:38:21,019 root   DEBUG    Added 100 proxies from SslProxy\n",
            "2021-05-13 17:38:21,021 root   DEBUG    Total proxies = 873\n",
            "2021-05-13 17:38:21,024 root   DEBUG    Filtered proxies = 873\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FaweI_Ksbcj"
      },
      "source": [
        "table = pd.read_csv('/content/drive/MyDrive/Project/Data/datasets/' + name)\n",
        "table = table[[colname for colname in table.columns if 'Unnamed:' not in colname]]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1Ue0bRGfstf"
      },
      "source": [
        "scraped_path = '/content/drive/MyDrive/Project/Data/Scraped/'\n",
        "\n",
        "if not path.exists(scraped_path):\n",
        "  mkdir(scraped_path)\n",
        "\n",
        "scraped_filename = scraped_path + name[:name.find('.csv')] + '_scraped.csv'\n",
        "\n",
        "old_cols = table.columns.to_list() \n",
        "\n",
        "scrape_cols = ['image', 'has_video', 'n_tiers', 'tiers_values', 'n_images', ' n_gifs', \n",
        "                             'n_websites', 'fb_linked', 'n_collab', 'collab_names']\n",
        "cols = old_cols + scrape_cols\n",
        "df = pd.DataFrame(columns=cols)\n",
        "\n",
        "if path.exists(scraped_filename):\n",
        "  df = pd.read_csv(scraped_filename)\n",
        "  # cut table to restart after last index of previous run\n",
        "  table = table[df.index.stop:]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6zHB6o_yVfB"
      },
      "source": [
        "# Scraping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRkf6NnK6n7r",
        "outputId": "988b0bbf-f9c9-468c-c227-f98c4e3e31f7"
      },
      "source": [
        "http_proxy  = None\n",
        "https_proxy = None\n",
        "proxy = None\n",
        "proxyDict = { \n",
        "              \"http\"  : http_proxy, \n",
        "              \"https\" : https_proxy, \n",
        "            }\n",
        "start = time.time()\n",
        "k = False\n",
        "fs = FuturesSession()\n",
        "sess = Session()\n",
        "r = fs.get(\"https://www.kickstarter.com\").result()\n",
        "soup = BeautifulSoup(r.text, 'html.parser')\n",
        "xcsrf = soup.find(\"meta\", {\"name\": \"csrf-token\"})[\"content\"]\n",
        "headers= {\n",
        "              \"x-csrf-token\": xcsrf\n",
        "          }\n",
        "query = \"\"\"\n",
        "query Campaign($slug: String!) {\n",
        "  project(slug: $slug) {\n",
        "    risks\n",
        "    story(assetWidth: 680)\n",
        "  }\n",
        "}\"\"\"\n",
        " \n",
        "last_10 = []\n",
        "c= 0\n",
        "\n",
        "for i, row in table.iterrows():\n",
        "  url = eval(row['urls'])['web']['project']\n",
        "  succesful = False\n",
        "  page = time.time()\n",
        "  slug = re.search('/projects/(.*)\\?', url).group(1)\n",
        "  url = re.search('(.*)\\?', url).group(1)\n",
        "  print(f\"------ Page {i}: {slug} ------\")\n",
        "  \n",
        "  while not succesful:\n",
        "    try:\n",
        "      rs = [fs.get(url), fs.post(\"https://www.kickstarter.com/graph\", proxies = proxyDict,\n",
        "          headers=headers,\n",
        "          json = {\n",
        "              \"operationName\":\"Campaign\",\n",
        "              \"variables\":{\n",
        "                  \"slug\": slug\n",
        "              },\n",
        "              \"query\": query\n",
        "          })]\n",
        " \n",
        "      time.sleep(1.5)\n",
        "      r = None\n",
        "      r = sess.get(url + '/creator_bio')\n",
        " \n",
        "      soup = BeautifulSoup(r.content, 'lxml')\n",
        "      ## Websites\n",
        "      websites = 0\n",
        "      if soup.find(\"ul\", {'class':'links list f5 bold'}):\n",
        "        websites = len(soup.find(\"ul\", {'class':'links list f5 bold'}).find_all('li'))\n",
        "          \n",
        "      ## Bio\n",
        "      bio = soup.find('div', {'class': 'readability'})\n",
        "      if bio:\n",
        "        bio_text = []\n",
        "        for p in bio.find_all('p'):\n",
        "            if p.find(text=True) != None:\n",
        "                bio_text.append(p.find(text=True))\n",
        "            \n",
        "        bio_text = ' '.join(bio_text)\n",
        "      else:\n",
        "        bio_text = None\n",
        "      ## Facebook\n",
        "      fb = soup.find(\"div\", {'class':\"facebook py2 border-bottom f5\"}) \n",
        "      fb_linked = fb.find(\"a\", {'class': 'popup'}) != None\n",
        "      \n",
        "      # Collaborators\n",
        "      n_collab = 0\n",
        "      collaborators = None\n",
        "      if soup.find(\"div\", {'class': 'pt3 pt7-sm mobile-hide row'}):\n",
        "        collaborators = soup.find(\"div\", {'class': 'pt3 pt7-sm mobile-hide row'}).findChildren('a')\n",
        "        n_collab = len(collaborators)\n",
        "      \n",
        "      # names\n",
        "      collab_names = []\n",
        "      if collaborators:\n",
        "        for col in collaborators:\n",
        "            collab_names.append(re.search(r'/profile/(.*?)/about', str(col)).group(1))   \n",
        " \n",
        "      r = None\n",
        "      r = rs[0].result()\n",
        "      soup = BeautifulSoup(r.content, 'lxml')\n",
        "      \n",
        "      ## Image\n",
        "      image = soup.find('img')['src']\n",
        "      ## Video\n",
        "      has_video = soup.find('video') is not None\n",
        "      ## Pledge tiers\n",
        "      tiers = soup.find_all(\"div\", {\"class\": \"pledge__info\"})\n",
        "      tiers_values = []\n",
        "      for tier in tiers:\n",
        "          s = str(tier.find(\"span\", {\"class\": \"money\"}))\n",
        "          if re.search(r'\\d+', s):\n",
        "            tiers_values.append(int(re.findall(r'\\d+', s)[0]))\n",
        "          else:\n",
        "            tiers_values.append('0')\n",
        "      n_tiers = len(tiers_values)\n",
        " \n",
        "      # time.sleep(random.lognormal(mean = 0.1, sigma=0.25))\n",
        "      r = None\n",
        "      r = rs[1].result()\n",
        "      result = r.json()\n",
        "      \n",
        "      story_html = result[\"data\"][\"project\"][\"story\"]\n",
        "      story = BeautifulSoup(story_html, 'html.parser')\n",
        "      n_gifs = len(story.find_all('img', {'class': \"fit js-lazy-image\"}))\n",
        "      n_images = len(story.find_all('img')) - n_gifs\n",
        "      \n",
        " \n",
        "      # text\n",
        "      story_text = ' '.join([p for p in story.find_all(text=True) if i not in ['\\n', ' ']])\n",
        " \n",
        "      risks = result[\"data\"][\"project\"][\"risks\"]\n",
        " \n",
        "      # time.sleep(random.lognormal(mean = 0.1, sigma=0.25))\n",
        "      \n",
        " \n",
        "      df.loc[i] = pd.Series(table.loc[i].values.tolist() + [image, has_video, n_tiers, tiers_values, n_images, n_gifs, websites,\n",
        "                      fb_linked, n_collab, collab_names], index = cols)\n",
        "      succesful = True\n",
        "      if time.time()-page < 2:\n",
        "        time.sleep(2 - (time.time() - page))\n",
        "      print('Time for this page was {}s'.format(round(time.time()-page, 2)))\n",
        "      \n",
        "      last_10.append(time.time()-page)\n",
        "      if len(last_10) == 11:\n",
        "        last_10.pop(0)\n",
        "        if sum([x >= 5 for x in last_10]) >= 5:\n",
        "          print('Proxy too slow')\n",
        "          proxy = proxy_list.pop(random.choice(len(proxy_list))).get_address()\n",
        "          if len(proxy_list) == 0:\n",
        "            req_proxy = RequestProxy()\n",
        "            proxy_list = req_proxy.get_proxy_list()\n",
        "          http_proxy  = 'http://' + proxy\n",
        "          https_proxy = 'https://' + proxy\n",
        "          proxyDict = { \n",
        "                        \"http\"  : http_proxy, \n",
        "                        \"https\" : https_proxy, \n",
        "                      }\n",
        "         \n",
        "          last_10 = []\n",
        " \n",
        "    except KeyboardInterrupt:\n",
        "      k = True\n",
        "      print('interrupted!')\n",
        "      break\n",
        "    \n",
        "    except:\n",
        "      if r and r.status_code == 200:\n",
        "        time.sleep(1.5)\n",
        "        print('Problems parsing, scraping skipped!!')\n",
        "        df.loc[i] = pd.Series(table.loc[i].values.tolist(), index = old_cols)\n",
        "        succesful =True\n",
        "      elif r and r.status_code == 429:\n",
        "        print(\"Too many requests, rotate ip\")\n",
        "        time.sleep(5)\n",
        "        proxy = proxy_list.pop(random.choice(len(good_proxies))).get_address()\n",
        "        if len(proxy_list) == 0:\n",
        "            req_proxy = RequestProxy()\n",
        "            proxy_list = req_proxy.get_proxy_list()\n",
        "        http_proxy  = 'http://' + proxy\n",
        "        https_proxy = 'https://' + proxy\n",
        "        proxyDict = { \n",
        "                      \"http\"  : http_proxy, \n",
        "                      \"https\" : https_proxy, \n",
        "                    }\n",
        "   \n",
        "      else:\n",
        "        print(\"Bad Proxy\")\n",
        "        time.sleep(5)\n",
        "        proxy = proxy_list.pop(random.choice(len(proxy_list))).get_address()\n",
        "        if len(proxy_list) == 0:\n",
        "            req_proxy = RequestProxy()\n",
        "            proxy_list = req_proxy.get_proxy_list()\n",
        "        http_proxy  = 'http://' + proxy\n",
        "        https_proxy = 'https://' + proxy\n",
        "        proxyDict = { \n",
        "                      \"http\"  : http_proxy, \n",
        "                      \"https\" : https_proxy, \n",
        "                    }\n",
        "        \n",
        "    \n",
        "    \n",
        "  if k:\n",
        "    break\n",
        "  \n",
        "  if i%500 == 0:\n",
        "    print(f'\\n\\n ----- Reached Page {i}, saving dataframe to {scraped_filename} ----- \\n\\n')\n",
        "    df.to_csv(scraped_filename, index=False)\n",
        " \n",
        "  \n",
        "print(f'Total time for {i - table.index.start} pages is {round(time.time()-start, 2)} seconds')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------ Page 10215: 1692006165/the-wall-americas-separation-of-church-and-state ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10216: thekobiechronicles/from-fatherless-to-fatherhood ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10217: ericatrembay/it-came-from-above-the-joplin-mo-tornado ------\n",
            "Time for this page was 2.19s\n",
            "------ Page 10218: ethanmarten/white-buffalo-an-american-prophecy-lakota-and-hopi ------\n",
            "Time for this page was 2.05s\n",
            "------ Page 10219: eastpointpictures/the-smash-brothers-series-production ------\n",
            "Time for this page was 2.42s\n",
            "------ Page 10220: btivie/the-drop-box ------\n",
            "Time for this page was 2.32s\n",
            "------ Page 10221: justinzimmerman/excalibur-comics-women-of-wonder-2011-documentary ------\n",
            "Time for this page was 2.04s\n",
            "------ Page 10222: orlive/hiv-a-whole-different-story-or-live ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10223: thehappyfilm/the-happy-film ------\n",
            "Time for this page was 2.04s\n",
            "------ Page 10224: theclubdoc/the-club-0 ------\n",
            "Time for this page was 2.02s\n",
            "------ Page 10225: smallfish/stripped-the-comics-documentary ------\n",
            "Time for this page was 3.58s\n",
            "------ Page 10226: annsfilms/millions-criedno-one-listened-a-hidden-truth ------\n",
            "Time for this page was 2.08s\n",
            "------ Page 10227: self-proclaimed/duke-and-the-king ------\n",
            "Time for this page was 2.17s\n",
            "------ Page 10228: 1751892223/the-sons-of-starcraft ------\n",
            "Time for this page was 2.05s\n",
            "------ Page 10229: 1465033211/help-need-distribution-funds-for-the-almond-tree ------\n",
            "Time for this page was 2.01s\n",
            "------ Page 10230: 844144068/adventures-in-killing-the-radio-star-tour-fundrais ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10231: 1044274020/merkato ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10232: 657184133/beyond-the-balkans ------\n",
            "Time for this page was 2.1s\n",
            "------ Page 10233: 859143778/where-the-yellowstone-goes ------\n",
            "Time for this page was 2.08s\n",
            "------ Page 10234: bestrong/be-strong-be-gentle-be-beautiful ------\n",
            "Time for this page was 2.23s\n",
            "------ Page 10235: 266682699/stuck-on-earth-going-where-no-band-has-gone-before ------\n",
            "Time for this page was 2.32s\n",
            "------ Page 10236: wolffjosh/my-village-my-lobster-a-documentary-film-project ------\n",
            "Time for this page was 2.02s\n",
            "------ Page 10237: 1941167757/incident-in-new-baghdad-oscar-qualifying-la-releas ------\n",
            "Time for this page was 2.08s\n",
            "------ Page 10238: calledtowalls/called-to-walls ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10239: 1218354395/breathin-the-eddy-zheng-story ------\n",
            "Time for this page was 2.03s\n",
            "------ Page 10240: 2050292259/wings-of-steel-the-film-0 ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10241: 1670101310/to-them-thats-gone-a-film-for-the-fallen ------\n",
            "Time for this page was 2.02s\n",
            "------ Page 10242: 1109075117/lost-and-found-series ------\n",
            "Time for this page was 2.08s\n",
            "------ Page 10243: 161417471/chicago-farmer-documentary ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10244: gayle/to-catch-a-dollar-muhammad-yunus-banks-on-america ------\n",
            "Time for this page was 2.01s\n",
            "------ Page 10245: 1556403687/flyin-miata-races-at-targa-newfoundland ------\n",
            "Time for this page was 2.14s\n",
            "------ Page 10246: mediastorm/a-darkness-visible-afghanistan ------\n",
            "Time for this page was 2.1s\n",
            "------ Page 10247: 1465054380/you-and-me-a-documentary-on-intimacy-in-dance-and ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10248: meatthezoo/me-at-the-zoo ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10249: thedurgas/the-durgas-rocking-the-caucasus ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10250: 206589381/linotype-the-film-final-push ------\n",
            "Time for this page was 2.15s\n",
            "------ Page 10251: 1824891397/beast-wishes-the-bob-and-kathy-burns-movie ------\n",
            "Time for this page was 2.01s\n",
            "------ Page 10252: 435193201/outdoorsmen-the-film ------\n",
            "Time for this page was 2.03s\n",
            "------ Page 10253: 777774294/in-chains-freeing-women-and-girls-from-sexual-slav ------\n",
            "Time for this page was 2.03s\n",
            "------ Page 10254: jayvery/the-jay-very-story ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10255: 281632469/altruistic-arcs-redux-documentary-about-social-ent ------\n",
            "Time for this page was 2.21s\n",
            "------ Page 10256: isleroyalewinter/fifty-lakes-one-island ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10257: barbershoppunk/barbershop-punk-protect-your-freedom-of-speech ------\n",
            "Time for this page was 2.4s\n",
            "------ Page 10258: 287538697/prisoners-and-patriots-japanese-internment-in-sant ------\n",
            "Time for this page was 2.18s\n",
            "------ Page 10259: arcmedia/untold-tales-of-the-comic-industry ------\n",
            "Time for this page was 2.04s\n",
            "------ Page 10260: 1991631952/help-get-sarah-palin-you-betcha-into-theaters ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10261: 1671759408/point-and-shoot ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10262: everydayheroes/everyday-heroes-a-fresh-look-at-caribbean-men ------\n",
            "Time for this page was 2.04s\n",
            "------ Page 10263: 1201262065/more-than-gold-the-rhino-rescue-project ------\n",
            "Time for this page was 2.09s\n",
            "------ Page 10264: 824005985/generation-a-autism-and-the-arts ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10265: 628470324/the-mexican-suitcase-gets-a-chance-for-academy-nom ------\n",
            "Time for this page was 2.01s\n",
            "------ Page 10266: 1672395135/ejkei-a-documentary-about-skateboarding-in-puerto ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10267: wehavedodgeball/we-have-dodgeball ------\n",
            "Time for this page was 2.07s\n",
            "------ Page 10268: 1522534378/bert-kreischer-on-the-road-a-documentary ------\n",
            "Time for this page was 2.07s\n",
            "------ Page 10269: jsween/queeryouthfilmproject ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10270: 1343865910/roaming-wild ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10271: shaneburley/a-documentary-about-eviction-resistance-and-housin ------\n",
            "Time for this page was 2.19s\n",
            "------ Page 10272: 1288019107/faiths-song ------\n",
            "Time for this page was 2.18s\n",
            "------ Page 10273: 600958914/paint-me-dark ------\n",
            "Time for this page was 2.22s\n",
            "------ Page 10274: 1003496538/the-chance-of-freedom-short-film ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10275: theredwoods/the-redwoods-tv-series ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10276: caicarney/nowhere-else ------\n",
            "Time for this page was 2.08s\n",
            "------ Page 10277: thejakemock/the-ropes-are-fine ------\n",
            "Time for this page was 2.05s\n",
            "------ Page 10278: 986291036/seven-hills ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10279: 109001691/film-funding-needed-for-christian-film-called-rede ------\n",
            "Time for this page was 2.3s\n",
            "------ Page 10280: 1892917087/a-vested-interest-movie-trailer ------\n",
            "Time for this page was 2.21s\n",
            "------ Page 10281: 334392997/the-way-forward-productions-ltd ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10282: 1644454611/confidential-deceit ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10283: tesswalker/civil-blood ------\n",
            "Time for this page was 2.09s\n",
            "------ Page 10284: 1310297780/kola ------\n",
            "Time for this page was 2.15s\n",
            "------ Page 10285: 1502576464/billionaire-at-pumapunku ------\n",
            "Time for this page was 2.08s\n",
            "------ Page 10286: 1310297780/kola-0 ------\n",
            "Time for this page was 2.26s\n",
            "------ Page 10287: 256133648/the-only-son ------\n",
            "Time for this page was 2.25s\n",
            "------ Page 10288: 1608079720/rat-race-an-independent-feature-film ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10289: 881503977/passing-clouds ------\n",
            "Time for this page was 2.36s\n",
            "------ Page 10290: 878346899/my-day ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10291: 1837713731/all-or-nothin ------\n",
            "Time for this page was 2.05s\n",
            "------ Page 10292: 1856178222/the-schiedam-parkmurder ------\n",
            "Time for this page was 2.04s\n",
            "------ Page 10293: 1447866008/dragged-up-short-gritty-fact-based-drama ------\n",
            "Time for this page was 2.24s\n",
            "------ Page 10294: 1461389778/the-pride ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10295: danafilm/dana ------\n",
            "Time for this page was 2.01s\n",
            "------ Page 10296: 1034136260/rock-star-0 ------\n",
            "Time for this page was 2.22s\n",
            "------ Page 10297: 7442341/feature-film-hard-and-soft ------\n",
            "Time for this page was 2.22s\n",
            "------ Page 10298: 1103748696/harsh ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10299: 1468335222/raw-the-film ------\n",
            "Time for this page was 2.26s\n",
            "------ Page 10300: 1567577298/trip ------\n",
            "Time for this page was 2.06s\n",
            "------ Page 10301: colorgreenfilms/brennan-manning-movie ------\n",
            "Time for this page was 2.07s\n",
            "------ Page 10302: 1304204549/parallel-the-film ------\n",
            "Time for this page was 2.41s\n",
            "------ Page 10303: troysheppard/all-in-my-head-a-film-about-drug-addiction-and-sui ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10304: 1606702023/help-me-make-a-indie-film-about-young-love-the-rea ------\n",
            "Time for this page was 2.13s\n",
            "------ Page 10305: 1639902667/crossroads-the-reunion ------\n",
            "Time for this page was 2.15s\n",
            "------ Page 10306: 1637467384/maggephah ------\n",
            "Time for this page was 2.25s\n",
            "------ Page 10307: 675621351/stop-het-nu ------\n",
            "Time for this page was 2.09s\n",
            "------ Page 10308: 693597383/the-execution-of-william-odeger ------\n",
            "Time for this page was 2.15s\n",
            "------ Page 10309: kordalenkaleb/the-making-of-picture-perfect ------\n",
            "Time for this page was 2.2s\n",
            "------ Page 10310: 11649426/desexed-the-book-and-the-movie ------\n",
            "Time for this page was 2.02s\n",
            "------ Page 10311: projectprivledged/project-privileged ------\n",
            "Time for this page was 2.07s\n",
            "------ Page 10312: 1526992428/the-last-of-our-days ------\n",
            "Time for this page was 2.12s\n",
            "------ Page 10313: 612419971/the-elephant-in-the-room-0 ------\n",
            "Time for this page was 2.0s\n",
            "------ Page 10314: 369650812/theatre-of-the-mind ------\n",
            "Time for this page was 2.07s\n",
            "------ Page 10315: 1286359920/forgotten ------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6l3x-zcsSTO"
      },
      "source": [
        "df.to_csv(scraped_filename, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}